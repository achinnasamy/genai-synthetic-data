import pandas as pd
from pyspark.sql import SparkSession
from ctgan import CTGAN

#Unlike Faker or other libraries which generates dummy data based on random patterns, CTGAN learns from the real data
# and can produce synthetic samples that resemble the original data distribution more closely.

class Session:
    def __init__(self, name):
        self.name = name

    def session_create(self):
        spark = SparkSession.builder.appName("CTGANSparkSession").getOrCreate()
        return spark

class SyntheticDataBuilder(Session):
    def __init__(self, quants):
        # Number of synthetic samples to be generated by CTGAN.
        self.quants = quants

    def create_dataframe(self):
        spark = Session.session_create(self)

        # Replace this with your actual data
        data = pd.read_csv("insurance.csv")

        # categorical features to be used in CTGAN
        categorical_features = ['age', 'sex', 'children', 'smoker', 'region']

        # Setting verbose=True displays detailed progress during CTGAN training.
        ctgan = CTGAN(verbose=True)

        # The number of epochs is the training iterations for CTGAN to learn from the data.
        ctgan.fit(data, categorical_features, epochs=200)

        synthetic_data = ctgan.sample(self.quants)
        synthetic_df = spark.createDataFrame(synthetic_data)
        synthetic_df.show()
        synthetic_df.write.csv("ctgan_generated.csv")


syn = SyntheticDataBuilder(1000)
syn.create_dataframe()
